# 알고리즘

> 알고리즘은 무조건 많이 풀어보고 다양한 유형들을 숙지하고 있는것이 최고의 방법!
>
> 코딩테스트는 어려운 문제는 없지만 내가 다양한 각도에서 문제를 해결하는 방법을 갖고 있는지 판단하는 척도
>
> > ### 파이썬 코딩테스트
> >
> > 대체로 코테에서 128~512MB로 메모리를 제한하는데 파이썬에서는 메모리제한이 걸리기 쉽다.
> >
> > | 데이터 개수 | 메모리 사용량 |
> > | ----------- | ------------- |
> > | 1,000       | 약 4KB        |
> > | 1,000,000   | 약 4MB        |
> > | 10,000,000  | 약 40MB       |
> >
> > 리스트크기가 1,000만 이상인 경우 메모리제한 이슈가 발생활 확률이 높으니 꼭 고려하자



## 그리디 (탐욕알고리즘)

### 💡 현재 상황에서 지금 당장 좋은 것만 고르는 방법. 현재 선택이 나중에 미칠영향은 고려하지 않는다.

> 일반적으로 암기가 필요없는 알고리즘이지만 나아가서 `플로이드 워셜`, `다익스트라`, '크루스칼' 등 특정 알고리즘을 미리 알고있어야 풀 수 있는 알고리즘도 있음. 따라서 많은 문제를 풀어보는 것이 가장 중요.
>
> 해당 문제를 풀기위한 최소한의 아이디어를 떠올려 반복적으로 당장 좋은것을 고르는 방법인지 검토해야함.



## 구현

### 💡현재 머릿속에 있는 알고리즘을 소스코드로 바꾸는 과정. 문법숙지 필수!  다양한 라이브러리 경험이 있으면 더 좋다!

> 풀이를 떠올리는 것은 쉽지만 코드로 옮기는 것이 어려운 문제. 보통 사소한 입력 조건등을 명시해 주고 문제의 길이가 긴 편.
>
>  #### 완전탐색: 모든 경우의 수를 다 계산하는 방법
>
>  #### 시뮬레이션: 문제에서 제시한 알고리즘을 한 단계씩 차례대로 직접 수행하는 문제
>
> 2차원 배열에서 방향벡터를 사용하는 문제가 자주 출제됨



## DFS & BFS

### 💡그래프를 탐색하기위한 대표적인 두 알고리즘

> #### 자료구조
>
> 데이터를 표현하고 관리하고 처리하기 위한 구조. DFS BFS 알고리즘을 위해 설명이 필요한 두가지의 자료구조 **stack** 과 **큐**
>
> > #### stack
> >
> > 흔히 박스쌓기로 비유. 아래에서 부터 위로 쌓고, 치울 때는 위에서부터 치운다.
> >
> > **선입후출(First In Last Out) 또는 후입선출(Last In First Out)**
> >
> > **ex**
> >
> > 삽입(5) 삽입(2) 삽입(3) 삽입(7) 삭제() 삽입(1) 삽입(4) 삭제() ....
> >
> > 5  2  3  (7)  1  (4)
> >
> > 최종 남은 stack 5231
>
> > #### queue
> >
> > 대기줄로 비유. 먼저 들어온 것이 먼저 나간다.
> >
> > 1 2 3 4 5 순으로 들어왔다면 호출도 1 2 3 4 5
>
> 
>
> > **큐 예제: 삽입(5) 삽입(2) 삽입(3) 삽입(7) 삭제() 삽입(1) 삽입(4) 삭제()**
> >
> > ``` python
> > from collection import deque
> > 
> > queue = deque()
> > 
> > queue.append(5)
> > queue.append(2)
> > queue.append(3)
> > queue.append(7)
> > queue.popleft()
> > queue.append(1)
> > queue.append(4)
> > queue.popleft()
> > 
> > print(queue)  # 5 2 3 1
> > queue.reverse()	 # 역순으로 바꿈
> > print(queue)  # 1 3 2 5
> > ```
> >
> > `queue` 라이브러리는 `list`와 비슷하지만 보다 연산속도가 빨라 코딩테스트에서 유리하다! `collection` 모듈은 대부분 코테에서도 채택해서 안심하고 사용할 수 있다



### DFS

> 깊이 우선 탐색(Depth-First-Search)라고 부르며, 그래프에서 깊은 부분을 우선적으로 탐색하는 알고리즘
>
> 1. 탐색 시작 노드를 스택에 삽입하고 방문처리
> 2. 스택의 최사단 노드에 인접하고 방문하지 않은 노드가 있으면 인접노드를 스택에 넣고 방문 처리. 방문하지 않은 인접노드가 없으면 스택 최상단 노드를 꺼냄
> 3. 2번 과정을 더 이상 수행할 수 없을 때까지 반복
>
> 주로 재귀함수`recursive function` 이용
>
> #### 그래프
>
> 그래프는 노트`Node`와 간선`Edge`로 표현되며 노드는 정점`Vertex`로 불리기도 한다.
>
> 그래프는 크게 두가지 방식으로 표현
>
> - 인접 행렬(Adjanceney Matrix): 2차원 배열로 그래프 연결관계를 표현하는 방식. 연결되지 않은 곳은 0 또는 무한 비용으로 처리
>
>   ``` python
>   INF = 9999999 # 무한비용
>   
>   graph = [
>       [0, 7, 5],
>       [7, 0, INF],
>       [5, INF, 0]
>   ]
>   ```
>
>   이 그래프는 0번 정점이 1, 2번 노드에 각각 7, 5 비용으로 연결
>
>   1번 정점이 0번에 만 연결, 2번 정점이 0번에만 연결되어 있음.
>
> - 인접 리스트(Adjanceney List): 리스트로 그래프의 연결관계를 표현하는 방식
>
>   > ```python
>   > graph = [[(1,7),(2,5)], [(0,7)], [(0,5)]
>   > ```
>   >
>   > 인접 행렬과 같은 연결상태를 인접 리스트로 표현함
>
> #### DFS method
>
> ``` python
> def DFS(graph, v, visited):
>     visited[v] = 1
>     for i in graph[v]:
>         if not visited[i]:
>             DFS(graph, i, visited)
> ```



### BFS

> 너비 우선 탐색(Breadth-First-Search) 가까운 노드부터 탐색하는 알고리즘. 주로 `queue` 이용
>
> 1. 탐색 시작 노드를 큐에 삽입하고 방문처리
> 2. 큐에서 노드를 꺼내 인접 노드중에 방문하지 않은 노드를 모두 큐에 삽입
> 3. 2번 과정을 더 이상 수행할 수 없을 때까지 반복
>
> #### BFS method
>
> ``` python
> from collection import deque
> 
> def BFS(graph, start, visited):
>     queue = deque([start])
>     visited[start] = 1
>     
>     while queue:
>         v = queue.popleft()
>         for i in graph[v]:
>             if not visited[i]:
>                 queue.append(i)
>                 visited[i] = 1
> ```



## 정렬

### 💡 데이터를 특정한 기준으로 나열하는 것

#### ex) 7 5 9 0 3 1 6 2 4 8 각 숫자가 적힌 카드를 오름차순으로 정렬하는 알고리즘

1. 선택정렬

   > 이중 가장 작은 데이터를 찾아 맨 앞에 데이터와 바꾸고, 맨 앞 데이터를 제외한 리스트에서 앞 과정을 반복. 가장 원시적인 방법(다소 느림)
   >
   > ```  python
   > array = [7, 5, 9, 0, 3, 1, 6, 2, 4, 8]
   > 
   > for i in range(len(array)):
   >     min_index = i
   >     for j in range(i+1, len(array)):
   >         if array[j] < array[min_index]:
   >             min_index = j
   >     array[i],array[min_index] = array[min_index],array[i]
   > ```
   >
   > **선택정렬의 시간복잡도**
   >
   > `N-1`번 만큼 가장 작은수를 찾아서 맨 앞으로 보내야한다. 따라서 `N + (N-1) + (N-2) + ... + 2` 식이 완성되고 줄여서 `N(N + 1) / 2` 값이 나온다.
   >
   > 시간복잡도는 가장 높은차수만을 판단하기에 **O(N^2)**이다.

2. 삽입정렬

   > 선택정렬보다 구현 난이도는 어렵지만 시간 측면에서 효율적임. 데이터를 하나씩 확인하며 적절한 위치에 삽입하는 알고리즘. 특정 데이터가 적절한 위치에 들어가기 이전에, 그 앞까지의 데이터는 이미 정렬되어있다고 가정한다.
   >
   > ``` python
   > array = [7, 5, 9, 0, 3, 1, 6, 2, 4, 8]
   > 
   > for i in range(1, len(array)):
   >     for j in range(i, 0, -1):
   >         if array[j] < array[j-1]:	# 한칸씩 왼쪽으로 움직이면서 자기보다 큰 값과는 자리바꿈
   >             array[j],array[j-1] = array[j-1], array[j]
   >         else:		# j보다 작은값이 왼쪽에 있으면 멈춤
   >             break
   > ```
   >
   > **삽입정렬의 시간복잡도**
   >
   > 이중 `for`문으로 선택정렬과 같게 **O(N^2)**이다. 실제로 계산해보아도 두 알고리즘은 비슷한 값이 나옴. 하지만 거의 정렬되어 있는상태에서는 삽입정렬은 퀵정렬보다 빠를 정도로 월등히 빠른속도를 보임.

3. 퀵정렬

   > 기준 데이터를 정하고 그 기준(피벗`pivot`)보다 큰 데이터와 작은 데이터의 위치를 바꾼다.
   >
   > > #### 피벗 설정하는 방법
   > >
   > > 호어 분항 방식 `Hoare Partition` (대표적인 방법)
   > >
   > > 1. 리스트에서 첫 번째 데이터를 피벗으로 정한다.
   > > 2. 왼쪽에서 부터 피벗보다 큰 데이터를 찾고, 오른쪽에서부터 피벗보다 작은 데이터를 찾는다.
   > > 3. 큰 데이터와 작은 데이터의 위치를 교환해준다.
   > > 4. 앞 과정을 계속 반복하다가, 왼쪽에서 온 값과 오른쪽에서 온 값이 서로 리스트를 교차할 때, 피벗보다 작은값과, 피벗의 위치를 교환해준다.
   > > 5. 이제 피벗을 기준으로 앞은 피벗보다 작은값, 뒤는 피벗보다 큰 값들로 나뉘었으니, 개별적으로 1에서 5번 과정을 반복해 정렬시킨다.
   > > 6. 피벗을 설정할 리스트의 길이가 1개가 되면 그 리스트는 종료.
   >
   > 
   >
   > **직관적인 퀵정렬 소스코드**
   >
   > ``` python
   > array = [7, 5, 9, 0, 3, 1, 6, 2, 4, 8]
   > 
   > def quick_sort(array, start, end):
   >     if start >= end:
   >         return
   >     pivot = start	# pivot은 시작 원소
   >     left = start + 1
   >     right = end
   >     
   >     while left < right:		# 왼쪽 오른쪽 값이 교차하면 반복문 중지
   >         
   >         while left <= end and array[left] <=array[pivot]:		
   >             # left가 끝 인덱스에 가지 않고, 피벗보다 작은값이면 큰 값 나올 때까지 반복
   >             left += 1
   >         
   >         while right > start and array[right] >= array[pivot]:	
   >             # right이 첫 인덱스에 가지 않고, 피벗보다 큰 값이면 작은 값 나올 때까지 반복
   >             right -= 1
   >         
   >         if left > right:
   >             # 큰 값 인덱스와 작은 값 인덱스가 교차했으면, 작은 값을 피벗으로 설정
   >             array[right], array[pivot] = array[pivot], array[right]
   >         else:
   >             # 엇갈리지 않았다면 큰 값 작은 값 교체
   >             array[right], array[left] = array[left], array[right]
   >         
   >         
   >     # 분할하여 퀵정렬 실행
   >     quick_sort(array, start, right-1)
   >     quick_sort(array, right+1, end)
   >     
   > quick_sort(array, 0, len(array)-1)
   > ```
   >
   > 
   >
   > **파이썬 장점을 살린 퀵정렬 소스코드**
   >
   > ```python
   > array = [7, 5, 9, 0, 3, 1, 6, 2, 4, 8]
   > 
   > def quick_sort(array):
   >     if len(array) <= 1:
   >         # 배열이 1개 이하면 종료
   >         return array
   >     
   >     pivot = array[0]	# 첫 인덱스 피벗설정
   >     tail = array[1:]	# 피벗을 제외한 리스트
   >     
   >     left_side = [x for x in tail if x <= pivot]		# pivot보다 작은값을 담은 왼쪽 부분
   >     right_side = [x for x in tail if x > pivot]		# pivot보다 큰 값을 담은 오른쪽 부분
   >     
   >     # 분할 이후 왼쪽 부분 + 피벗 + 오른쪽 부분 에서 각각 정렬을 수행하고, 전체 리스트 반환
   >     return quick_sort(left_side) + [pivot] + quick_sort(right_side)
   > ```
   >
   > **퀵정렬의 시간복잡도**
   >
   > **O(NlogN)**으로 앞서 다룬 정렬 알고리즘들에 비해 월등히 빠른 편이다. 분할이 1번 일어 날 때마다 1/2 씩 기하 급수적으로 줄기에 가장 빠를때(항상 절반씩 나눠질 때)`logN`이다.  최악의 경우 `N^2` 까지 갈 수 있어 평균값은 `NlogN` 으로 나타낸다

4. 계수정렬

   > 특정한 조건이 부합할 때만 사용할 수 있는 알고리즘.
   >
   > 데이터의 크기 범위가 제한되어 정수 형태로 표현할 수 있을 때만 사용할 수 있고, 일반적으로 최댓값과 최솟값의 차이가 1,000,000 이하일 때 효과적이다.
   >
   > 별도의 리스트를 선언하고, 정렬할 리스트들의 값을 선언한 리스트의 인덱스에 순차적으로 넣어 해당 리스트 값을 1씩 증가시킨다.
   >
   > ``` python
   > array = [7, 5, 9, 0, 3, 1, 6, 2, 9, 1, 4, 8, 0, 5, 2]
   > 
   > count = [0]*(len(array)+1)
   > 
   > for i in range(len(array)):
   >  count[array[i]] += 1
   > 
   > for i in range(len(count)):
   >  for j in rnage(count[i]):
   >      print(i, end=' ')
   > ```
   >
   > **계수정렬의 시간복잡도**
   >
   > 모든 데이터가 양의 정수이고, 최대값이 K일 때, 최악의 경우에도 수행시간은 `O(N+K)`를 보장한다. 하지만 별도의 리스트를 생성하므로 공간복잡도 이슈가 발생할 수 있으니 데이터 양을 잘 보고 판단해서 사용해야한다.
   
5. 파이썬의 정렬 라이브러리

   > - 함수 `sorted(array, (key))`: 시간복잡도: `O(NlogN)`, 퀵정렬과 비슷한 알고리즘으로 구성됨
   >
   > - 배열 메서드 `.sort((key))`: 리스트에 내장된 메서드. 반환값이 없고, 배열자체적으로 정렬함.
   >
   >   두 라이브러리 모두 `key`값에 매개변수를 대입해 매개변수를 기준으로 정렬시킬 수 있음
   >
   >   **ex**
   >
   >   ``` python
   >   # 1
   >   array.sort(key=lambda x: x[1])
   >   # 2
   >   def setting(array):
   >   	return array[1]
   >             
   >   result = sorted(array, key=setting)
   >   ```



## 이진탐색

### 💡배찾으려는 데이터와 중간점 위치에 있는 데이터를 반복해서 비교해서 탐색 (기본적으로 배열은 정렬되어있어야 함)

**시간복잡도**: 원소의 개수가 절반씩 사라지므로 `O(logN)`

> - 재귀함수로 구현한 소스코드
>
>   ``` python
>   def binary_search(array, target, start, end):
>       if start > end:			# 첫 시작점과 끝점이 교차 => 못찾은 것
>           return None
>       mid = (start + end) // 2		# 중간점 인덱스 반환
>               
>       if array[mid] == target:
>           return mid
>       elif array[mid] > target:
>           return binary_search(array, target, start, mid-1)
>       else:
>           return binary_search(array, target, mid+1, end)
>               
>   N, target = map(int, input().split())
>   # 배열 길이와 타겟넘버
>           
>   array = list(map(int, input().split()))
>   # 배열
>   result = binary_search(array, target, 0, N)
>   if result == None:
>       print(False)
>   else:
>       print(result)
>   ```
>
>   
>
>   - 반복문으로 구현한 소스코드
>
>     ``` python
>     def binary_search(array, target, start, end):
>                         
>         while start <= end:
>             mid = (start + end) // 2		# 중간점 인덱스 반환
>                             
>             if array[mid] == target:
>                 return mid
>             elif array[mid] > target:
>                 end = mid - 1
>             else:
>                 start = mid + 1
>                                 
>     	return None
>     ```
>
>   
>
>   이진탐색은 시간복잡도가 좋은만큼 대용량 데이터 처리에 자주 쓰인다. 또한 코딩테스트에도 자주 나오는 알고리즘 이기에 만약 많은 양의 정렬된 데이터에서 특정값을 찾아야한다면 이진탐색을 사용하자

### 트리 자료구조

> DB는 내부적으로 대용량 데이터 처리에 적합한 트리구조를 활용하여 항상 데이터가 정렬되어 있다. DB탐색은 이진탐색과 조금 다르지만, 유사한 방법을 사용도록 설계되어있다.
>
> #### 트리
>
> 트리는 그래프 구조의 일종이며, 많은 양의 데이터를 관리하는 목적으로 쓰이는 자료구조다. 노드와 노드의 연결로 이루어져있고 각 노드는 정보들을 갖고있다.
>
> **트리의 특징**
>
> 1. 트리 최상단 노드를 루트노드라고 함
> 2. 노드는 부모와 자식 관계로 표현
> 3. 트리에서 일부를 떼어내도 트리구조이며 서브트리라고 함
>
> 
>
> > #### 이진탐색트리
> >
> > ![이진탐색트리](README_사진/이진탐색트리.png)
> >
> > 트리 구조중 가장 간단한 형태.
> >
> > 부모 노드보다 왼쪽 자식 노드가 작다.
> >
> > 부모 노드보다 오른쪽 자식 노드가 크다.
> >
> > ➡ **왼쪽 자식노드 < 부모노드 < 오른쪽 자식노드**
>
> #### 💡 데이터 빠르게 입력받기
>
>  ``` python
>  import sys
>  # 하나의 문자열 데이터 입력받기
>  input_data = sys.stdin.readline().rstrip()
>  ```
>
> 데이터를 입력받을 때 마지막 `Enter` 를 누르면서 줄바꿈 기호가 들어가기 때문에 `rstrip`을 꼭 마지막에 사용해주자



## DP 다이나믹 프로그래밍(동적 프로그래밍)

### 💡 한번 계산 문제는 다시 계산하지 않는 알고리즘 ➡ 메모리 절약

> 대표적인 DP ➡ **피보나치수열**
>
> **DP사용조건**
>
> 1. 큰 문제를 작은 문제로 나눌 수 있다
> 2. 작은 문제에서 구한 정답은 그것을 포함한 큰 문제에서도 동일하다.
>
> #### ex 피보나치 수열 소스코드
>
> ``` python
> def fibo(n):
>     if n == 1 or n == 2:
>         return 2
>     return fibo(n-1) + fibo(n-2)
> ```
>
> 늘어나는 재귀함수들 중에서 분명 같은 값을 계산하는 함수가 존재하기 때문에 피보나치 수열은 `n`값이 커질수록 생겨야 하는 아래 차수 항들이 기하급수적으로 늘어난다. (시간복잡도: `O(2^N)`) ➡ 메모이제이션을 활용해 한 번 구현한 값을 저장해 필요할 때 호출하면 수고를 줄일 수 있다.
>
> > **메모이제이션**
> >
> > 한 번 구현한 값을 리스트에 저장하는 것
>
> #### 메모이제이션을 적용한 피보나치 수열코드
>
> ```python
> d = [0]*100		# 구현한 값을 저장할 메모이제이션 리스트
> def fibo(n):
>     if n == 1 || n == 2:
>         return 1
>     
>     if d[x] != 0:		# 리스트에 있는 값이라면 바로 호출
>         return d[x]
>     
>     d[x] = fibo(n-1) + fibo(n-2)
>     return d[x]
> ```
>
> 이렇게 구현하면 같은 문제도 메모리가 효울적으로 한 번씩만 사용되어 시간복잡도가 `O(N)` 이다.
>
> 피보나치처럼 큰 문제를 호출하기 위해 작은 문제들을 계속 호출하는 방식을 하향식 `Top down` 방식이라한다.
>
> 반대로 작은문제를 계속 호출해 큰 문제를 해결하는 방식은 상향식 `Bottom up` 이라한다.
>
> #### Bottom up 피보나치
>
> ``` python
> d = [0]*100
> d[1] = 1
> d[2] = 1
> for i in range(3, n+1):
>     d[i] = d[i-1] + d[i-2]
> print(d[n])
> ```
>
> 
>
> 추가로 재귀함수는 깊이가 1000 이상일 시 `recursion depth`  관련 오류가 발생할 수 있다. 이런 경우
>
> ``` python
> import sys
> sys.setrecursionlimit()
> ```
>
> 을 호출해 완화하여 풀 수 있다.



## 최단경로

### 💡 == 길찾기문제

> 다양한 종류가 많고, 상황에맞는 알고리즘들이 이미 많이 정리되어있다.**다익스트라, 플로이드 워셜, 밸만포드**
>
> > ### 다익스트라
> >
> > #### 음의노드가 없을 때, 여러개의 노드 중 특정 한 노드에서 출발하여 다른노드로 가는 각각의 최단경로를 구하는 알고리즘
> >
> > 실제 GPS 기본 알고리즘으로 채택되고 한다.
> >
> > 다익스트라 최단경로는 매번 최소비용을 택하기 때문에 그리디로 분류되기도 한다.
> >
> > 1. 출발노드 설정
> >
> > 2. 최단 거리 테이블 초기화
> >
> > 3. 방문하지 않은 노드 중 최단거리가 가장 짧은 노드선택 (방문처리)
> >
> > 4. 해당 노드를 거쳐 다른노드로 가는 비용을 계산하여 최단 거리 테이블을 갱신
> >
> >    > 현재위치에서 노드로 가는 비용+현재 노드까지 누적비용 과 기존에 설정된 비용을 비교하여 최소비용을 선택
> >
> > 5. `3` 과 `4` 를반복
> >
> > **다익스트라의 두가지 구현 방법**
> >
> > - 구현하기 쉽지만 느리게 동작하는 코드
> > - 구현은 어렵지만 빠르게 동작하는 코드
> >
> > ``` python
> > import sys
> > input = sys.stdin.readline
> > 
> > INF = 1e9  # 10억, 갈 수 없는 노드 즉 무한비용
> > N, M = map(int, input().split())    # 노드개수, 간선개수
> > start = int(input())                # 시작노드
> > 
> > graph = [[] for _ in range(N+1)]
> > # 각 노드에 연결되어 있는 노드에 대한 정보를 담는 리스트 만들기
> > 
> > visited = [False]*(N+1)
> > # 방문한 노드 체크를 위한 리스트
> > 
> > distance = [INF]*(N+1)
> > # 최단거리 테이블 초기화
> > 
> > for _ in range(M):
> >     a, b, c = map(int,input().split())      # a 노드에서 b 노드로 가는 비용 c
> >     graph[a].append((b,c))                  # 연결된 노드와 비용 입력
> > 
> > def smallest_cost():
> >     '''
> >     방문하지 않은 노드 중에서 , 가장 최단 거리가 짧은 노드의 번호를 반환
> >     '''
> >     min_value = INF
> >     index = 0
> >     for i in range(1, N+1):
> >         if distance[i] < min_value and not visited[i]:
> >             min_value = distance[i]
> >             index = i
> >     return index
> > 
> > def dijstra(start):
> >     distance[start] = 0         # 시작노드 거리 0
> >     visited[start] = True       # 시작노드 방문처리
> >     for j in graph[start]:      # 시작노드가 연결된 곳들의 정보 j[0]: 연결노드 번호 j[1]: 비용
> >         distance[j[0]] = j[1]   # 연결된 노드의 거리 갱신
> > 
> >     for i in range(N-1):
> >         now = smallest_cost()   		   # =방문하지 않은 곳 중 제일 적은 비용 드는노드 번호
> >         visited[now] = True     		   # 방문처리
> >         for j in graph[now]:    		   # 현재노드가 연결된 곳들의 정보 j[0]: 연결노드 번호 j[1]: 비용
> >             cost = distance[now] + j[1]     # 현재위치까지의 비용 + 현재위치에서 연결된 노드로 가는 비용
> >             if cost < distance[j[0]]:       # 이전에 계산된 최소 비용보다 cost가 적다면
> >                 distance[j[0]] = cost       # 갱신
> > 
> > dijstra(start)
> > ```
> >
> > **시간복잡도**: `O(V^2)` V는 정점의 개수. 단계마다 방문하지 않은 노드 중 최단 거리가 가장 짧은 노드를 선태갛기 위해 1차원 리스트의 모든 원소를 순차탐색 하기 때문.
> >
> > 
> >
> > #### 개선된 다익스트라
> >
> > **힙(Heap)**을 사용하여 시간복잡도를 `O(ElogV)` 까지 줄일 수 있다
> >
> > > **Heap**
> > >
> > > 우선순위 큐(Priority Queue)를 규현하기 위해 사용하는 자료구조중 하나.
> > >
> > > 우선순위 큐는 **우선순위가 가장 높은 데이터를 가장 먼저 제거하는 큐**
> > >
> > > |                   자료구조 | 추출되는 데이터             |
> > > | -------------------------: | :-------------------------- |
> > > |                 스택 Stack | 가장 나중에 삽입된 데이터   |
> > > |                   큐 Queue | 가장 먼저 삽입된 데이터     |
> > > | 우선순위 큐 Priority Queue | 가장 우선순위가 높은 데이터 |
> > >
> > > 대부분의 프로그래밍 언어에서 우선순위 큐 라이브러리를 제공한다. 따라서 일반적인 코테에서 우리가 직접 힙 자료구조부터 작성해 우선순위 큐를 구현할 일은 없다.
> > >
> > > 파이썬에서는 우선순위 큐가 필요할 때 `Priority Queue` 보다는 일반적으로 `heapq`가 더 빠르게 동작하기 때문에 수행시간이 제한된 상황에서 `heapq`를 사용하는것을 권장한다.
> > >
> > > 보통 정수형 자료형의 변수가 우선순위의 값을 표현.
> > >
> > > - **최소힙(Min Heap)**: 값이 가장 낮은 데이터 먼저 삭제
> > > - **최대힙(Max Heap)**: 값이 가장 큰 데이터 먼저 삭제
> > >
> > > 최소힙을 최대힙 처럼 사용하기 위해 최소힙 의 값을 음수부호(-)를 넣어 삽입하였다가 추출시 한 번 더 붙여서 양수로 바꿔 사용하는 기술도 있음
> > >
> > > | 우선순위 큐 구현방식 | 삽입 시간 | 삭제 시간 |
> > > | -------------------- | --------- | --------- |
> > > | 리스트               | O(1)      | O(N)      |
> > > | 힙                   | O(logN)   | O(logN)   |
> >
> > 1. 출발 노드를 제외한 모든 노드 무한비용 처리
> > 2. 출발노드까지 비용 0 과 출발노드 정보를 (거리, 노드) 튜플형태로 최소 힙에 삽입 ex (0, 1)
> > 3. 힙에서 현재 가장 가까운 노드를 추출
> > 4. 추출한 노드에서 거리가 가장 가까운 노드부터 꺼내 갈수있는 노드와 거리를 `2`번과 같은 형태로 최소힙에 삽입
> > 5. `3` 번과 `4`번 반복.
> > 6. 최종적으로 갈 수 있는 노드가 다 삭제되고, 이미 방문한 튜플이 있다면 무시(삭제)
> >
> > ```  python
> > import heapq
> > import sys
> > input = sys.stdin.readline
> > 
> > INF = 1e9  # 10억, 갈 수 없는 노드 즉 무한비용
> > N, M = map(int, input().split())    # 노드개수, 간선개수
> > start = int(input())                # 시작노드
> > 
> > graph = [[] for _ in range(N+1)]
> > # 각 노드에 연결되어 있는 노드에 대한 정보를 담는 리스트 만들기
> > 
> > distance = [INF]*(N+1)
> > # 최단거리 테이블 초기화
> > 
> > for _ in range(M):
> >     a, b, c = map(int,input().split())      # a 노드에서 b 노드로 가는 비용 c
> >     graph[a].append((b,c))                  # 연결된 노드와 비용 입력
> > 
> > def dijstra(start):
> >     '''
> >     방문하지 않은 노드 중에서 , 가장 최단 거리가 짧은 노드의 번호를 반환
> >     '''
> >     q = []
> >     heapq.heappush(q, (0, start))
> >     # 시작 노드로 가는 경로는 0으로 설정 후 q에 삽입
> >     distance[start] = 0
> >     while q:        # q가 비어있지 않으면 반복
> >         dist, now = heapq.heappop(q)
> >         # 가장 최단 거리가 짧은 노드에 대한 정보 꺼내기
> >         if distance[now] < dist:
> >             continue
> >         # 처리된 적 있는 노드는 무시
> >         for i in graph[now]:
> >             cost = dist + i[1]
> >             if cost < distance[i[0]]:
> >                 distance[i[0]] = cost
> >                 heapq.heappush(q,(cost, i[0]))
> >                 # 현재 노드를 거쳐서, 다른 노드를 이동하는 거리가 더 짧은경우 갱신
> > ```
> >
> > **시간복잡도**: `O(ElogV)`. 일반 다익스트라와 다르게 한번 처리한 노드는 `continue`로 지나간다.따라서 `while`반복문은 노드 개수 V 이상 반복하지 않는다. V번 반복될 때마다 각각 자신과 연결된 모든 간선들을 확인한다.
> >
> > 따라서 현재 우선순위큐에서 꺼낸 노드와 연결된 다른 노드들을 확인하는 총 횟수는 최대간선의 개수 만큼 연산이 수행 될 수 있다.
> >
> > #### 시간복잡도 계산
> >
> > 삽입의 경우 힙은 `logN`이 걸리고 E개의 간선을 모두 넣으니 `ElogE` 가 된다 이때 중복간선은 포함하지 않으니 E는 항상 V^2 보다 작다. 왜냐면 모든 노드끼리 서로 다 연결되어 있다고 할 때 간선의 개수를 약 V^2개로 볼 수 있다. 따라서 `logE`는 `logV^2`보다 작기에 이때 `O(logE)`는 `Olog(V^2)`가 되고 `O(2logV)` 가 되어 최종적으로 간단히 `O(ElogV)` 로 나타낼 수 있다. 
>
> 
>
> > ### 플루이드 워셜
> >
> > #### 모든 지점에서 모든 다른 지점 까지의 최단경로를 구하는 알고리즘
> >
> > 다익스트라와 다른점
> >
> > - 다익스트라는 한 지점에서 모든 지점으로 가는 최단 경로
> > - 플루이드 워셜은 방문여부를 따지지 않음
> > - 플루이드 워셜은 N개의 노드를 N번에 맞게 단계를 반복하고 점화식에 맞게 2차원 리스트를 개선하기 때문에 DP
> >
> > 노드의 개수가 N개일 때, N번의 단계를 수행해 하나의 노드당 `O(N^2)` 연산이 이뤄지고 결과적으로 시간복잡도는 **O(N^2)**
> >
> >  ``` python
> >  INF = int(1e9)
> >  
> >  # n, m = 노드개수, 간선개수
> >  n = int(input())
> >  m = int(input())
> >  
> >  # 인덱스 값을 쉽게 생각하기 위해 n+1 x n+1 배열, 모든 값 무한으로초기화
> >  matrix = [[INF] * (n+1) for _ in range(n+1)]
> >  
> >  # 자기 자신으로는 0으로 치환
> >  for i in range(1, n+1):
> >      matrix[i][i] = 0
> >  
> >  # 간선 정보 그래프에 입력
> >  for _ in range(m):
> >      a, b, c = map(int, input().split())
> >      matrix[a][b] = c
> >  
> >  # 점화식에 따라 플루이드 워셜 알고리즘 수행
> >  for k in range(1, n+1):
> >      for i in range(1, n+1):
> >          for j in range(1, n+1):
> >              matrix[i][j] = min(matrix[i][j], matrix[i][k] + matrix[k][j])
> >  
> >  # 결과 출력
> >  for r in range(1, n+1):
> >      for c in range(1, n+1):
> >          if matrix[r][c] == INF:
> >              print('INFINITY', end=' ')
> >          else:
> >              print(matrix[r][c], end=' ')
> >      print()
> >  ```

